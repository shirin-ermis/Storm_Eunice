{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import os\n",
    "import seaborn as sns\n",
    "import random \n",
    "import scipy as sc\n",
    "import statsmodels.api as sm\n",
    "import scipy.stats as stats\n",
    "import cartopy.crs as ccrs\n",
    "import pygrib\n",
    "import cfgrib\n",
    "\n",
    "sns.set_theme(style=\"white\")\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "random.seed(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data in pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from MED-R Preindustrial and increased, as before\n",
    "directory_exp = '/network/group/aopp/predict/AWH012_LEACH_NASTORM/DATA/MED-R/EXP/'\n",
    "\n",
    "experiments = ['incr', 'pi']\n",
    "cfpf = ['cf', 'pf']  # control and perturbed are treated equally\n",
    "inits = {'pi' : ['b2nq_2022-02-10', 'b2nn_2022-02-14', 'b2ns_2022-02-16'], \n",
    "           'incr' : ['b2nr_2022-02-10', 'b2no_2022-02-14', 'b2nt_2022-02-16']}  # members for incr and pi runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# empty data frame to be filled later\n",
    "south_df = pd.DataFrame({'lat': [], \n",
    "                         'lon' : [],  \n",
    "                         'cfpf' : [], \n",
    "                         'member' : [], \n",
    "                         'init' : [],\n",
    "                         'time' : [],\n",
    "                         'fg10' : []})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import lat, lon values\n",
    "experiment = 'pi'\n",
    "init = inits['pi'][0]\n",
    "cont = 'cf'\n",
    "\n",
    "lat = xr.open_dataset(os.path.join(directory_exp,experiment,'EU025/sfc',cont,init+'.nc')).latitude.values\n",
    "lon = xr.open_dataset(os.path.join(directory_exp,experiment,'EU025/sfc',cont,init+'.nc')).longitude.values\n",
    " \n",
    "# Import time steps, NB there are three sets of time steps depending on the initialisation date\n",
    "fridays = []\n",
    "for init in inits['pi']:  # time stamps are the same across experiments pi and icnr\n",
    "    time = xr.open_dataset(os.path.join(directory_exp,experiment,'EU025/sfc',cont,init+'.nc')).time.values\n",
    "    fridays.append((time > pd.Timestamp(2022,2,18, 0)) & (time < pd.Timestamp(2022,2,18, 18)))\n",
    "\n",
    "# Defining box to analyse winds, south england and wales\n",
    "lat1 = 52.2\n",
    "lat2 = 50.3\n",
    "lon1 = -6\n",
    "lon2 = 1.3\n",
    "\n",
    "# Create mask\n",
    "south_england = {'lat': (lat < lat1) & (lat > lat2), 'lon': (lon < lon2) & (lon > lon1)}\n",
    "\n",
    "# Import time steps, NB there are three sets of time steps depending on the initialisation date\n",
    "fridays = []\n",
    "for init in inits['pi']:  # time stamps are the same across experiments pi and icnr\n",
    "    time = xr.open_dataset(os.path.join(directory_exp,experiment,'EU025/sfc',cont,init+'.nc')).time.values\n",
    "    fridays.append((time > pd.Timestamp(2022,2,18, 0)) & (time < pd.Timestamp(2022,2,18, 18)))\n",
    "\n",
    "# create a grid for lat and lon of the southern uk patch used above\n",
    "llat, llon = np.meshgrid(lon, lat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill data frame\n",
    "members = 50\n",
    "for experiment in experiments:\n",
    "    for init in inits[experiment]:\n",
    "        for cont in cfpf:\n",
    "            \n",
    "            # import full data set in file\n",
    "            data = xr.open_dataset(os.path.join(directory_exp,experiment,'EU025/sfc',cont,init+'.nc'))\n",
    "            \n",
    "            # store data in data frame with meta data\n",
    "            if cont == 'cf':  # distinguish between cfpf because members in pf\n",
    "                length = len(data.fg10.values.flatten())\n",
    "                number_timesteps = len(data.time.values)\n",
    "                adding = pd.DataFrame({'lat': np.repeat(llat.flatten(), number_timesteps), \n",
    "                                        'lon' : np.repeat(llon.flatten(), number_timesteps), \n",
    "                                        'cfpf' : np.tile(cont, length), \n",
    "                                        'member' : np.tile(-1, length), \n",
    "                                        'init' : np.tile(init, length), \n",
    "                                        'time': np.repeat(data.time.values.flatten(), len(lat)*len(lon)), \n",
    "                                        'fg10' : data.fg10.values.flatten()})\n",
    "                south_df = pd.merge(south_df, adding,\n",
    "                                    how = 'outer')\n",
    "            \n",
    "            elif cont == 'pf': \n",
    "                next\n",
    "                # for member in range(members):\n",
    "                #     length = len(data.fg10.values[:,member,:,:].flatten())\n",
    "                #     number_timesteps = len(data.time.values)\n",
    "                #     adding = pd.DataFrame({'lat': np.repeat(llat.flatten(), number_timesteps), \n",
    "                #                            'lon' : np.repeat(llon.flatten(), number_timesteps), \n",
    "                #                            'cfpf' : np.tile(cont, length),\n",
    "                #                            'member' : np.tile(member, length), \n",
    "                #                            'init' : np.tile(init, length), \n",
    "                #                            'time': np.repeat(data.time.values.flatten(), len(lat)*len(lon)), \n",
    "                #                            'fg10' : data.fg10.values[:,member,:,:].flatten()})\n",
    "                #     south_df = pd.merge(south_df, adding,\n",
    "                #                         how = 'outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "storm_eunice39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e85e7c9027c9ef342f521c50884794b3ff4e0d77b330915340a6a92aa790fc1e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
